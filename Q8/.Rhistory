library(ggplot2)
library(dplyr)
N <- 200 # number of points per class
D <- 2 # dimensionality, we use 2D data for easy visualization
K <- 2 # number of classes, binary for logistic regression
X <- data.frame(credit_card=double(), bank_balance=double()) # data matrix (each row = single example, can view as xy coordinates)
y <- data.frame() # class labels
set.seed(56)
for (j in (1:K)){
# t, m are parameters of parametric equations x1, x2
t <- seq(0,10000,length.out = N)
# add randomness
#print (t)
m <- rnorm(N, j+500, 250)
Xtemp <- data.frame(x1 = 3*t , x2 = abs(m - t))
ytemp <- data.frame(matrix(j-1, N, 1))
X <- rbind (X, Xtemp)
y <- rbind (y, ytemp)
}
X
data <- cbind(X,y)
data
colnames(data) <- c('credit_card', 'bank_balance', 'default')
#sigmoid function, inverse of logit
sigmoid <- function(z){1/(1+exp(-z))}
#cost function
cost <- function(theta, X, y){
m <- length(y) # number of training examples
h <- sigmoid(X %*% theta)
J <- (t(-y)%*%log(h)-t(1-y)%*%log(1-h))/m
J
}
#gradient function
grad <- function(theta, X, y){
m <- length(y)
h <- sigmoid(X%*%theta)
grad <- (t(X)%*%(h - y))/m
grad
}
logisticReg <- function(X, y){
#remove NA rows
X <- na.omit(X)
y <- na.omit(y)
#add bias term and convert to matrix
X <- mutate(X, bias =1)
#move the bias column to col1
X <- as.matrix(X[, c(ncol(X), 1:(ncol(X)-1))])
y <- as.matrix(y)
#initialize theta
theta <- matrix(rep(0, ncol(X)), nrow = ncol(X))
#use the optim function to perform gradient descent
costOpti <- optim(theta, fn = cost, gr = grad, X=X, y=y)
#return coefficients
return(costOpti$par)
}
logisticProb <- function(theta, X){
X <- na.omit(X)
#add bias term and convert to matrix
X <- mutate(X, bias =1)
X <- as.matrix(X[,c(ncol(X), 1:(ncol(X)-1))])
return(sigmoid(X%*%theta))
}
logisticPred <- function(prob){
return(round(prob, 0))
}
# training
theta <- logisticReg(X, y)
prob <- logisticProb(theta, X)
pred <- logisticPred(prob)
mylogit <- glm (default~credit_card+bank_balance, data=data, family="binomial")
summary(mylogit)
theta
library(ISLR)
library(ISLR)
library('ISLR')
installed.packages('ISLR')
library(ISLR)
'
installed.packages('ISLR')
instal.packages('ISLR')
install.packages('ISLR')
library(ISLR)
data <- Default
data
data['student'] <- apply(data['student'], 1, function(x) {if(x=='No') return (0) else return (1)})
data['default'] <- apply(data['default'], 1, function(x) {if(x=='No') return (0) else return (1)})
data
train_index <- sample.int(nrow(data), size=0.75*nrow(data))
train <- data[train_index,]
test <- data[-train_index,]
min_bal <- min(test['balance'])
max_bal <- max(test['balance'])
min_income <- min(test['income'])
max_income <- max(test['income'])
train['balance'] <- apply(train['balance'], 1, function(x) return ((x-min_bal)/(max_bal-min_bal)))
train['income'] <- apply(train['income'], 1, function(x) return ((x-min_income)/(max_income-min_income)))
x_train <- train[,-1]
y_train <- train[,1]
test['balance'] <- apply(test['balance'], 1, function(x) return ((x-min_bal)/(max_bal-min_bal)))
test['income'] <- apply(test['income'], 1, function(x) return ((x-min_income)/(max_income-min_income)))
x_test <- test[,-1]
y_test <- test[,1]
train['balance'] <- sapply(train['balance'], normalize)
normalize <- function(x){
return ((x-min(x)/max(x)-min(x)))
}
train['balance'] <- sapply(train['balance'], normalize)
train['income'] <- sapply(train['income'], normalize)
x_train <- train[,-1]
y_train <- train[,-1]
x_test <- train[,-1]
x_train <- train[,-1]
y_train <- train[,1]
x_test <- train[,-1]
y_test <- train[,1]
logisticReg <- function(X,Y, lr=0.1){
params <- rep(0,ncol(x_train)+1)
for(i in 1:10){
for(row in 1:nrow(X)){
x <- as.numeric(c(list(1),X[row,]))
pred <- as.double(1/as.double(1+exp(-(x%*%params))))
loss <- Y[row] - pred
for(p in 1:length(params)){
params[p] <- params[p] + lr*x[p]*loss
}
}
}
return(params)
}
getPred <- function(x){
x <- as.numeric(c(list(1),x))
return(1/(1+exp(-(x%*%params))))
}
getClass <- function(x){
if(x>=0.5)
return(1)
return(0)
}
model <- glm(default ~ student+balance+income, data=train,family=binomial)
params <- logisticReg(x_trqin, y_train)
params <- logisticReg(x_train, y_train)
params
pred <- sapply(apply(x_train, 1, getPred), getClass)
pred
predLib <- sapply(predict(model, x_train, type='response'), getClass)
predLib
print('Confustion matrix')
table(pred, t_train)
table(pred, x_train)
table(pred, y_train)
print('CM for library')
table(predLib, y_train)
params
model$coefficients
